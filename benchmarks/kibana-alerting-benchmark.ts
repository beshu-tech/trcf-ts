/**
 * Performance benchmarks for Kibana alerting use case
 * Focus: mono-variable time series, scoring performance, state serialization
 */

import { performance } from 'perf_hooks';
import * as zlib from 'zlib';
import * as fs from 'fs';
import { ThresholdedRandomCutForest, SimplifiedRCF, OptimizedRCF, ForestMode, TransformMethod } from '../src';

interface KibanaMetrics {
  // Scoring metrics (most critical for alerting)
  scoringLatencyP50: number;  // median scoring time (ms)
  scoringLatencyP99: number;  // 99th percentile (ms)
  scoringThroughput: number;  // points/second

  // State serialization metrics
  stateSize: number;          // bytes
  compressedStateSize: number; // bytes with gzip
  serializationTime: number;   // ms
  deserializationTime: number; // ms

  // Memory metrics
  memoryPerPoint: number;     // bytes per point in sliding window
  totalMemoryMB: number;       // total memory usage

  // Streaming metrics
  incrementalUpdateTime: number; // ms to add single point
  windowSize: number;           // effective window size

  // Accuracy metrics (for alerting)
  timeToFirstAlert: number;    // points until ready to alert
  falsePositiveRate: number;   // estimated based on threshold
}

export class KibanaAlertingBenchmark {

  /**
   * Create a configured TRCF for mono-variable time series
   */
  private static createMonoVariableTRCF(shingleSize: number = 4): {
    trcf: ThresholdedRandomCutForest,
    rcf: any
  } {
    // For mono-variable with shingling
    const dimensions = 1 * shingleSize;

    // Optimized settings for alerting
    const rcf = new OptimizedRCF({
      dimensions,
      shingleSize,
      numberOfTrees: 30,  // Balance between accuracy and performance
      sampleSize: 256,     // Standard window size
      timeDecay: 0.001     // Slow decay for long time series
    });

    const trcf = new ThresholdedRandomCutForest({
      dimensions: dimensions,  // Use full dimensions (1 * shingleSize)
      shingleSize: 1,          // Shingling handled externally
      forestMode: ForestMode.STANDARD,
      transformMethod: TransformMethod.NORMALIZE, // Handle varying scales
      anomalyRate: 0.01,   // 1% expected anomaly rate
      outputAfterFraction: 0.1  // Start alerting after 10% of data
    });

    trcf.setForest(rcf);
    return { trcf, rcf };
  }

  /**
   * Benchmark scoring performance (most critical for alerting)
   */
  static benchmarkScoring(): Pick<KibanaMetrics,
    'scoringLatencyP50' | 'scoringLatencyP99' | 'scoringThroughput'> {

    const { trcf } = this.createMonoVariableTRCF();

    // Warmup with typical time series pattern
    for (let i = 0; i < 1000; i++) {
      const value = Math.sin(i * 0.1) + (Math.random() - 0.5) * 0.1;
      // Create shingled input (4 values for shingleSize=4)
      const input = new Array(4).fill(value);
      trcf.process(input, i * 1000); // 1 second intervals
    }

    // Measure scoring latency
    const latencies: number[] = [];
    const testPoints = 10000;

    const startBatch = performance.now();
    for (let i = 0; i < testPoints; i++) {
      const value = Math.sin(i * 0.1) + (Math.random() - 0.5) * 0.1;

      const start = performance.now();
      const input = new Array(4).fill(value);
      const result = trcf.process(input, (1000 + i) * 1000);
      latencies.push(performance.now() - start);

      // Simulate anomaly
      if (i % 1000 === 500) {
        const anomalyValue = Math.sin(i * 0.1) + 5.0; // Spike
        const anomalyInput = new Array(4).fill(anomalyValue);
        trcf.process(anomalyInput, (1000 + i) * 1000 + 500);
      }
    }
    const totalTime = performance.now() - startBatch;

    // Calculate percentiles
    latencies.sort((a, b) => a - b);
    const p50 = latencies[Math.floor(latencies.length * 0.5)];
    const p99 = latencies[Math.floor(latencies.length * 0.99)];

    return {
      scoringLatencyP50: p50,
      scoringLatencyP99: p99,
      scoringThroughput: (testPoints / totalTime) * 1000
    };
  }

  /**
   * Benchmark state serialization (critical for distributed systems)
   */
  static benchmarkSerialization(): Pick<KibanaMetrics,
    'stateSize' | 'compressedStateSize' | 'serializationTime' | 'deserializationTime'> {

    const { trcf, rcf } = this.createMonoVariableTRCF();

    // Train with realistic data
    for (let i = 0; i < 5000; i++) {
      const value = Math.sin(i * 0.01) * (1 + 0.1 * Math.sin(i * 0.001)) + (Math.random() - 0.5) * 0.05;
      trcf.process([value], i * 1000);
    }

    // Create state object
    const state = {
      rcfState: {
        dimensions: rcf.getDimensions(),
        numberOfTrees: rcf.getNumberOfTrees(),
        sampleSize: rcf.getSampleSize(),
        totalUpdates: rcf.getTotalUpdates(),
        // In real implementation, would include tree states
        trees: [] // Placeholder - would contain actual tree data
      },
      trcfState: {
        totalUpdates: trcf.getTotalUpdates(),
        lastTimestamp: Date.now(),
        thresholds: {
          // Would include actual threshold data
          anomalyRate: 0.01,
          currentThreshold: 2.5
        }
      }
    };

    // Measure serialization
    const serializeStart = performance.now();
    const jsonState = JSON.stringify(state);
    const serializationTime = performance.now() - serializeStart;

    // Measure compression
    const compressed = zlib.gzipSync(Buffer.from(jsonState));

    // Measure deserialization
    const deserializeStart = performance.now();
    const restored = JSON.parse(jsonState);
    const deserializationTime = performance.now() - deserializeStart;

    return {
      stateSize: Buffer.byteLength(jsonState),
      compressedStateSize: compressed.length,
      serializationTime,
      deserializationTime
    };
  }

  /**
   * Benchmark streaming performance (for continuous monitoring)
   */
  static benchmarkStreaming(): Pick<KibanaMetrics,
    'incrementalUpdateTime' | 'memoryPerPoint' | 'totalMemoryMB'> {

    const { trcf } = this.createMonoVariableTRCF();

    // Get initial memory
    if (global.gc) global.gc();
    const memStart = process.memoryUsage().heapUsed;

    // Process initial window
    const windowSize = 1000;
    for (let i = 0; i < windowSize; i++) {
      const value = Math.sin(i * 0.1) + (Math.random() - 0.5) * 0.1;
      trcf.process([value], i * 1000);
    }

    if (global.gc) global.gc();
    const memAfterWindow = process.memoryUsage().heapUsed;

    // Measure incremental updates
    const updateLatencies: number[] = [];
    for (let i = 0; i < 1000; i++) {
      const value = Math.sin((windowSize + i) * 0.1) + (Math.random() - 0.5) * 0.1;

      const start = performance.now();
      trcf.process([value], (windowSize + i) * 1000);
      updateLatencies.push(performance.now() - start);
    }

    if (global.gc) global.gc();
    const memFinal = process.memoryUsage().heapUsed;

    const avgUpdateTime = updateLatencies.reduce((a, b) => a + b) / updateLatencies.length;
    const memoryPerPoint = (memAfterWindow - memStart) / windowSize;
    const totalMemoryMB = (memFinal - memStart) / (1024 * 1024);

    return {
      incrementalUpdateTime: avgUpdateTime,
      memoryPerPoint,
      totalMemoryMB
    };
  }

  /**
   * Test anomaly detection quality (for alerting accuracy)
   */
  static benchmarkAlertingQuality(): Pick<KibanaMetrics,
    'timeToFirstAlert' | 'falsePositiveRate' | 'windowSize'> {

    const { trcf } = this.createMonoVariableTRCF(4); // 4-point shingle

    let firstAlertPoint = -1;
    let falsePositives = 0;
    let truePositives = 0;
    const testSize = 10000;

    for (let i = 0; i < testSize; i++) {
      // Normal pattern with known anomalies
      let value = Math.sin(i * 0.1) + (Math.random() - 0.5) * 0.1;
      let isAnomaly = false;

      // Inject known anomalies
      if (i % 1000 === 500) {
        value += 3.0; // Spike anomaly
        isAnomaly = true;
      }

      const result = trcf.process([value], i * 1000);

      if (result.anomalyGrade > 0) {
        if (firstAlertPoint === -1) {
          firstAlertPoint = i;
        }

        if (isAnomaly) {
          truePositives++;
        } else {
          falsePositives++;
        }
      }
    }

    return {
      timeToFirstAlert: firstAlertPoint,
      falsePositiveRate: falsePositives / (testSize - 10), // Exclude actual anomalies
      windowSize: 256 * 4 // sampleSize * shingleSize
    };
  }

  /**
   * Run complete benchmark suite for Kibana alerting
   */
  static runFullBenchmark(): KibanaMetrics {
    console.log('Running Kibana Alerting Performance Benchmarks...\n');

    const scoring = this.benchmarkScoring();
    console.log('âœ“ Scoring benchmark complete');

    const serialization = this.benchmarkSerialization();
    console.log('âœ“ Serialization benchmark complete');

    const streaming = this.benchmarkStreaming();
    console.log('âœ“ Streaming benchmark complete');

    const alerting = this.benchmarkAlertingQuality();
    console.log('âœ“ Alerting quality benchmark complete\n');

    return {
      ...scoring,
      ...serialization,
      ...streaming,
      ...alerting
    };
  }

  /**
   * Print formatted report for Kibana use case
   */
  static printKibanaReport(metrics: KibanaMetrics): void {
    console.log('=' .repeat(60));
    console.log('KIBANA ALERTING PERFORMANCE REPORT');
    console.log('=' .repeat(60));

    console.log('\nðŸ“Š SCORING PERFORMANCE (Critical for Real-time Alerting)');
    console.log(`  Median Latency (P50): ${metrics.scoringLatencyP50.toFixed(3)} ms`);
    console.log(`  99th Percentile (P99): ${metrics.scoringLatencyP99.toFixed(3)} ms`);
    console.log(`  Throughput: ${metrics.scoringThroughput.toFixed(0)} points/second`);

    console.log('\nðŸ’¾ STATE SERIALIZATION (For Distributed Systems)');
    console.log(`  State Size: ${(metrics.stateSize / 1024).toFixed(2)} KB`);
    console.log(`  Compressed Size: ${(metrics.compressedStateSize / 1024).toFixed(2)} KB`);
    console.log(`  Compression Ratio: ${(100 * (1 - metrics.compressedStateSize / metrics.stateSize)).toFixed(1)}%`);
    console.log(`  Serialization Time: ${metrics.serializationTime.toFixed(3)} ms`);
    console.log(`  Deserialization Time: ${metrics.deserializationTime.toFixed(3)} ms`);

    console.log('\nðŸ”„ STREAMING PERFORMANCE (For Continuous Monitoring)');
    console.log(`  Incremental Update: ${metrics.incrementalUpdateTime.toFixed(3)} ms`);
    console.log(`  Memory per Point: ${metrics.memoryPerPoint.toFixed(0)} bytes`);
    console.log(`  Total Memory: ${metrics.totalMemoryMB.toFixed(2)} MB`);

    console.log('\nðŸš¨ ALERTING QUALITY');
    console.log(`  Time to First Alert: ${metrics.timeToFirstAlert} points`);
    console.log(`  False Positive Rate: ${(metrics.falsePositiveRate * 100).toFixed(3)}%`);
    console.log(`  Effective Window: ${metrics.windowSize} points`);

    console.log('\nâœ… KIBANA REQUIREMENTS CHECK:');
    console.log(`  Real-time Scoring: ${metrics.scoringLatencyP99 < 10 ? 'âœ“ PASS' : 'âœ— FAIL'} (<10ms P99)`);
    console.log(`  High Throughput: ${metrics.scoringThroughput > 10000 ? 'âœ“ PASS' : 'âœ— FAIL'} (>10K pts/sec)`);
    console.log(`  Fast Serialization: ${metrics.serializationTime < 100 ? 'âœ“ PASS' : 'âœ— FAIL'} (<100ms)`);
    console.log(`  Compact State: ${metrics.compressedStateSize < 100000 ? 'âœ“ PASS' : 'âœ— FAIL'} (<100KB)`);
    console.log(`  Low FP Rate: ${metrics.falsePositiveRate < 0.01 ? 'âœ“ PASS' : 'âœ— FAIL'} (<1%)`);

    console.log('\n' + '=' .repeat(60));
  }
}

// Main execution
if (require.main === module) {
  console.log('TRCF Performance Benchmarks for Kibana Alerting');
  console.log('Optimized for mono-variable time series\n');

  const metrics = KibanaAlertingBenchmark.runFullBenchmark();
  KibanaAlertingBenchmark.printKibanaReport(metrics);

  // Save results
  const filename = `kibana-benchmark-${new Date().toISOString().slice(0, 10)}.json`;
  fs.writeFileSync(filename, JSON.stringify(metrics, null, 2));
  console.log(`\nDetailed results saved to ${filename}`);
}